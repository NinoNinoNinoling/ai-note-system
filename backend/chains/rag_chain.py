# backend/chains/rag_chain.py
import os
import json
import numpy as np
from typing import List, Dict, Optional
from config.settings import Config

try:
    import faiss
    from sentence_transformers import SentenceTransformer
    RAG_AVAILABLE = True
except ImportError:
    RAG_AVAILABLE = False
    print("âš ï¸ RAG íŒ¨í‚¤ì§€ (faiss, sentence-transformers)ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

class RAGChain:
    """Retrieval-Augmented Generation ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.available = RAG_AVAILABLE
        
        if not self.available:
            return
            
        try:
            # ë‹¤êµ­ì–´ ì§€ì› ì„ë² ë”© ëª¨ë¸
            self.model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')
            self.dimension = 384  # ëª¨ë¸ì˜ ë²¡í„° ì°¨ì›
            
            # FAISS ì¸ë±ìŠ¤ ì´ˆê¸°í™”
            self.index = faiss.IndexFlatIP(self.dimension)  # ì½”ì‚¬ì¸ ìœ ì‚¬ë„
            self.notes_data = []  # ë…¸íŠ¸ ë©”íƒ€ë°ì´í„° ì €ì¥
            
            # íŒŒì¼ ê²½ë¡œ ì„¤ì •
            self.index_file = Config.RAG_INDEX_PATH
            self.metadata_file = Config.RAG_METADATA_PATH
            
            # ê¸°ì¡´ ì¸ë±ìŠ¤ ë¡œë“œ
            self.load_index()
            
            print("âœ… RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            print(f"âŒ RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.available = False
    
    def is_available(self) -> bool:
        """RAG ì‹œìŠ¤í…œ ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€"""
        return self.available
    
    def add_note(self, note_id: int, title: str, content: str) -> bool:
        """ë…¸íŠ¸ë¥¼ ë²¡í„°í™”í•´ì„œ ì¸ë±ìŠ¤ì— ì¶”ê°€"""
        if not self.available:
            return False
            
        try:
            # ì œëª©ê³¼ ë‚´ìš© í•©ì³ì„œ ì„ë² ë”©
            text = f"ì œëª©: {title}\n\n{content}"
            
            # ë²¡í„°í™”
            embedding = self.model.encode([text])
            embedding = embedding / np.linalg.norm(embedding)  # ì •ê·œí™”
            
            # FAISS ì¸ë±ìŠ¤ì— ì¶”ê°€
            self.index.add(embedding.astype('float32'))
            
            # ë©”íƒ€ë°ì´í„° ì €ì¥
            self.notes_data.append({
                "note_id": note_id,
                "title": title,
                "content_preview": content[:200] + "..." if len(content) > 200 else content,
                "full_content": content,
                "content_length": len(content)
            })
            
            # ì €ì¥
            self.save_index()
            print(f"âœ… ë…¸íŠ¸ {note_id} ë²¡í„°í™” ì™„ë£Œ")
            return True
            
        except Exception as e:
            print(f"âŒ ë…¸íŠ¸ ë²¡í„°í™” ì˜¤ë¥˜: {e}")
            return False
    
    def search_similar_notes(self, query: str, k: int = 5) -> List[Dict]:
        """ì¿¼ë¦¬ì™€ ìœ ì‚¬í•œ ë…¸íŠ¸ ê²€ìƒ‰"""
        if not self.available or self.index.ntotal == 0:
            return []
            
        try:
            # ì¿¼ë¦¬ ë²¡í„°í™”
            query_embedding = self.model.encode([query])
            query_embedding = query_embedding / np.linalg.norm(query_embedding)
            
            # ìœ ì‚¬í•œ ë²¡í„° ê²€ìƒ‰
            scores, indices = self.index.search(query_embedding.astype('float32'), min(k, self.index.ntotal))
            
            results = []
            for i, (score, idx) in enumerate(zip(scores[0], indices[0])):
                if 0 <= idx < len(self.notes_data):
                    note = self.notes_data[idx].copy()
                    note['similarity_score'] = float(score)
                    note['rank'] = i + 1
                    results.append(note)
            
            return results
            
        except Exception as e:
            print(f"âŒ ìœ ì‚¬ ë…¸íŠ¸ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return []
    
    def get_context_for_query(self, query: str, k: int = 3) -> str:
        """ì¿¼ë¦¬ì— ëŒ€í•œ ì»¨í…ìŠ¤íŠ¸ ìƒì„± (AI ëª¨ë¸ì— ì „ë‹¬ìš©)"""
        similar_notes = self.search_similar_notes(query, k)
        
        if not similar_notes:
            return "ê´€ë ¨ëœ ë…¸íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        context_parts = ["ë‹¤ìŒì€ ê´€ë ¨ëœ ë…¸íŠ¸ë“¤ì…ë‹ˆë‹¤:\n"]
        
        for i, note in enumerate(similar_notes, 1):
            context_parts.append(f"[ë…¸íŠ¸ {i}] {note['title']}")
            context_parts.append(f"ë‚´ìš©: {note['full_content']}")
            context_parts.append(f"ìœ ì‚¬ë„: {note['similarity_score']:.3f}\n")
        
        return "\n".join(context_parts)
    
    def save_index(self) -> bool:
        """ì¸ë±ìŠ¤ì™€ ë©”íƒ€ë°ì´í„° ì €ì¥"""
        if not self.available:
            return False
            
        try:
            # FAISS ì¸ë±ìŠ¤ ì €ì¥
            if self.index.ntotal > 0:
                faiss.write_index(self.index, self.index_file)
            
            # ë©”íƒ€ë°ì´í„° ì €ì¥
            with open(self.metadata_file, 'w', encoding='utf-8') as f:
                json.dump(self.notes_data, f, ensure_ascii=False, indent=2)
            
            return True
            
        except Exception as e:
            print(f"âŒ ì¸ë±ìŠ¤ ì €ì¥ ì˜¤ë¥˜: {e}")
            return False
    
    def load_index(self) -> bool:
        """ê¸°ì¡´ ì¸ë±ìŠ¤ì™€ ë©”íƒ€ë°ì´í„° ë¡œë“œ"""
        if not self.available:
            return False
            
        try:
            # FAISS ì¸ë±ìŠ¤ ë¡œë“œ
            if os.path.exists(self.index_file):
                self.index = faiss.read_index(self.index_file)
                print(f"âœ… ê¸°ì¡´ FAISS ì¸ë±ìŠ¤ ë¡œë“œ ì™„ë£Œ ({self.index.ntotal}ê°œ ë²¡í„°)")
            
            # ë©”íƒ€ë°ì´í„° ë¡œë“œ
            if os.path.exists(self.metadata_file):
                with open(self.metadata_file, 'r', encoding='utf-8') as f:
                    self.notes_data = json.load(f)
                print(f"âœ… ë©”íƒ€ë°ì´í„° ë¡œë“œ ì™„ë£Œ ({len(self.notes_data)}ê°œ ë…¸íŠ¸)")
            
            return True
            
        except Exception as e:
            print(f"âŒ ì¸ë±ìŠ¤ ë¡œë“œ ì˜¤ë¥˜: {e}")
            return False
    
    def rebuild_index(self, notes: List[Dict]) -> bool:
        """ì „ì²´ ì¸ë±ìŠ¤ ì¬êµ¬ì¶•"""
        if not self.available:
            return False
            
        print("ğŸ”„ RAG ì¸ë±ìŠ¤ ì¬êµ¬ì¶• ì‹œì‘...")
        
        try:
            # ê¸°ì¡´ ì¸ë±ìŠ¤ ì´ˆê¸°í™”
            self.index = faiss.IndexFlatIP(self.dimension)
            self.notes_data = []
            
            # ëª¨ë“  ë…¸íŠ¸ ë‹¤ì‹œ ì¶”ê°€
            success_count = 0
            for note in notes:
                if self.add_note(note['id'], note['title'], note['content']):
                    success_count += 1
            
            print(f"âœ… RAG ì¸ë±ìŠ¤ ì¬êµ¬ì¶• ì™„ë£Œ! ({success_count}/{len(notes)}ê°œ ì„±ê³µ)")
            return True
            
        except Exception as e:
            print(f"âŒ ì¸ë±ìŠ¤ ì¬êµ¬ì¶• ì˜¤ë¥˜: {e}")
            return False
    
    def get_stats(self) -> Dict:
        """RAG ì‹œìŠ¤í…œ í†µê³„ ì •ë³´"""
        return {
            "available": self.available,
            "indexed_notes": len(self.notes_data),
            "vector_count": self.index.ntotal if self.available else 0,
            "model_name": "paraphrase-multilingual-MiniLM-L12-v2" if self.available else None,
            "dimension": self.dimension if self.available else None
        }
    
    def clear_index(self) -> bool:
        """ì¸ë±ìŠ¤ ì™„ì „ ì‚­ì œ"""
        if not self.available:
            return False
            
        try:
            # ë©”ëª¨ë¦¬ìƒ ì¸ë±ìŠ¤ ì´ˆê¸°í™”
            self.index = faiss.IndexFlatIP(self.dimension)
            self.notes_data = []
            
            # íŒŒì¼ ì‚­ì œ
            if os.path.exists(self.index_file):
                os.remove(self.index_file)
            if os.path.exists(self.metadata_file):
                os.remove(self.metadata_file)
            
            print("âœ… RAG ì¸ë±ìŠ¤ ì™„ì „ ì‚­ì œ ì™„ë£Œ")
            return True
            
        except Exception as e:
            print(f"âŒ ì¸ë±ìŠ¤ ì‚­ì œ ì˜¤ë¥˜: {e}")
            return False

# ì „ì—­ RAG ì²´ì¸ ì¸ìŠ¤í„´ìŠ¤
rag_chain = RAGChain()